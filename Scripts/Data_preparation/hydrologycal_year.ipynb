{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Calculating the hydrological year means for all variables in the study"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8432942c30e504dc"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgeopandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mgpd\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T18:03:59.995355Z",
     "start_time": "2024-09-27T18:03:59.508962100Z"
    }
   },
   "id": "60a2d74c37cca4b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Water Levels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a614f6d3e5b8763"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/raw_data/Water_Level_ANA.csv', usecols = ['NivelConsistencia', 'Data', 'Media'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d02d1d8dec739dcb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only rows where NivelConsistencia is 1\n",
    "df = df[df['NivelConsistencia'] == 1]\n",
    "df['Data'] = pd.to_datetime(df['Data'], format='%d/%m/%Y')\n",
    "#Extract the year and month from the index\n",
    "df['Year'] = df['Data'].dt.year\n",
    "df['Month'] = df['Data'].dt.month\n",
    "#Group by Month and calculate the sum of precipitation for each station within each month\n",
    "df = df.groupby(['Year', 'Month']).mean()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb38ff9f4a3ea3b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hidro_months = ['5', '6', '7', '8', '9', '10', '11', '12', '1', '2','3', '4']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd25e19cea88bab0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from itertools import cycle, islice\n",
    "df[\"hydro_month\"] = list(islice(cycle(hidro_months), len(df)))\n",
    "df = df.drop(df.index[:8])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a8acc7f93338e58"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "years = [str(num) for num in range(1901, 2023) for _ in range(12)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3b4bf58bf9011bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"hydro_year\"] = list(islice(cycle(years), len(df)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9aae8e3e31aa3186"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"hydro_year\"] = list(islice(cycle(years), len(df)))\n",
    "df.tail()\n",
    "\n",
    "df['Media'] = df['Media'].astype(float)\n",
    "df['hydro_year'] = df['hydro_year'].astype(int)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68654debe46fb323"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_year = df.groupby('hydro_year').mean()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44aaf659f5c86a66"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_year = df_year.reset_index()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb9eeb4cac6f9df2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_year.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd3753a0064578a4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_year.to_csv('Data/ANA_WL.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "117095d24668db94"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Runoff"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9268d7be76ad04"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "Q = pd.read_csv('Data/raw_data/Runoff_ANA.csv')\n",
    "Q['Data'] = pd.to_datetime(Q['Data'], format='%d/%m/%Y')\n",
    "Q.head()\n",
    "df = Q"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T18:00:28.497410400Z",
     "start_time": "2024-09-27T18:00:28.445478500Z"
    }
   },
   "id": "f2260b56526b539f"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "hidro_months = ['3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '1', '2']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T18:00:29.143482700Z",
     "start_time": "2024-09-27T18:00:29.105028200Z"
    }
   },
   "id": "d8d9461044b3b4d5"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from itertools import cycle, islice"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T18:00:29.659755100Z",
     "start_time": "2024-09-27T18:00:29.640249600Z"
    }
   },
   "id": "592c963ab44681be"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "    EstacaoCodigo  NivelConsistencia       Data  Hora  MediaDiaria  \\\n10       67100000                  2 1964-09-01   NaN            1   \n11       67100000                  2 1964-10-01   NaN            1   \n12       67100000                  2 1964-11-01   NaN            1   \n13       67100000                  2 1964-12-01   NaN            1   \n14       67100000                  2 1965-01-01   NaN            1   \n\n    MetodoObtencaoVazoes    Maxima    Minima     Media  DiaMaxima  ...  \\\n10                     1   690.645   641.876   659.628          1  ...   \n11                     1   787.328   659.937   705.294         30  ...   \n12                     1  1020.572   817.675   933.462         24  ...   \n13                     1  1329.296  1049.302  1229.939         29  ...   \n14                     1  1545.048  1324.490  1454.582         21  ...   \n\n    Vazao23Status  Vazao24Status  Vazao25Status  Vazao26Status  Vazao27Status  \\\n10            1.0            1.0            1.0            1.0            1.0   \n11            1.0            1.0            1.0            1.0            1.0   \n12            1.0            1.0            1.0            1.0            1.0   \n13            1.0            1.0            1.0            1.0            1.0   \n14            1.0            1.0            1.0            1.0            1.0   \n\n    Vazao28Status  Vazao29Status  Vazao30Status  Vazao31Status  hydro_month  \n10            1.0            1.0            1.0            NaN            1  \n11            1.0            1.0            1.0            1.0            2  \n12            1.0            1.0            1.0            NaN            3  \n13            1.0            1.0            1.0            1.0            4  \n14            1.0            1.0            1.0            1.0            5  \n\n[5 rows x 79 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EstacaoCodigo</th>\n      <th>NivelConsistencia</th>\n      <th>Data</th>\n      <th>Hora</th>\n      <th>MediaDiaria</th>\n      <th>MetodoObtencaoVazoes</th>\n      <th>Maxima</th>\n      <th>Minima</th>\n      <th>Media</th>\n      <th>DiaMaxima</th>\n      <th>...</th>\n      <th>Vazao23Status</th>\n      <th>Vazao24Status</th>\n      <th>Vazao25Status</th>\n      <th>Vazao26Status</th>\n      <th>Vazao27Status</th>\n      <th>Vazao28Status</th>\n      <th>Vazao29Status</th>\n      <th>Vazao30Status</th>\n      <th>Vazao31Status</th>\n      <th>hydro_month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>67100000</td>\n      <td>2</td>\n      <td>1964-09-01</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>690.645</td>\n      <td>641.876</td>\n      <td>659.628</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>67100000</td>\n      <td>2</td>\n      <td>1964-10-01</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>787.328</td>\n      <td>659.937</td>\n      <td>705.294</td>\n      <td>30</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>67100000</td>\n      <td>2</td>\n      <td>1964-11-01</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1020.572</td>\n      <td>817.675</td>\n      <td>933.462</td>\n      <td>24</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>67100000</td>\n      <td>2</td>\n      <td>1964-12-01</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1329.296</td>\n      <td>1049.302</td>\n      <td>1229.939</td>\n      <td>29</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>67100000</td>\n      <td>2</td>\n      <td>1965-01-01</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1545.048</td>\n      <td>1324.490</td>\n      <td>1454.582</td>\n      <td>21</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 79 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"hydro_month\"] = list(islice(cycle(hidro_months), len(df)))\n",
    "df = df.drop(df.index[:10])\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T18:00:30.620850500Z",
     "start_time": "2024-09-27T18:00:30.599647300Z"
    }
   },
   "id": "deacf7881043f1ca"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "     EstacaoCodigo  NivelConsistencia       Data  Hora  MediaDiaria  \\\n699       67100000                  1 2022-02-01   NaN            1   \n700       67100000                  1 2022-03-01   NaN            1   \n701       67100000                  1 2022-04-01   NaN            1   \n702       67100000                  1 2022-05-01   NaN            1   \n703       67100000                  1 2022-06-01   NaN            1   \n\n     MetodoObtencaoVazoes    Maxima    Minima     Media  DiaMaxima  ...  \\\n699                     1  1102.199  1010.538  1064.722         26  ...   \n700                     1  1297.883  1102.199  1176.588         31  ...   \n701                     1  1422.217  1283.357  1360.572         21  ...   \n702                     1  1491.803  1394.359  1446.903         29  ...   \n703                     1  1541.801  1483.986  1515.262         27  ...   \n\n     Vazao24Status  Vazao25Status  Vazao26Status  Vazao27Status  \\\n699            NaN            NaN            NaN            NaN   \n700            1.0            1.0            1.0            1.0   \n701            1.0            1.0            1.0            1.0   \n702            1.0            1.0            1.0            1.0   \n703            NaN            NaN            NaN            NaN   \n\n     Vazao28Status  Vazao29Status  Vazao30Status  Vazao31Status  hydro_month  \\\n699            NaN            0.0            0.0            0.0            6   \n700            1.0            1.0            1.0            1.0            7   \n701            1.0            1.0            1.0            0.0            8   \n702            1.0            1.0            1.0            1.0            9   \n703            NaN            NaN            2.0            0.0           10   \n\n     hydro_year  \n699        2022  \n700        2022  \n701        2022  \n702        2022  \n703        2022  \n\n[5 rows x 80 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EstacaoCodigo</th>\n      <th>NivelConsistencia</th>\n      <th>Data</th>\n      <th>Hora</th>\n      <th>MediaDiaria</th>\n      <th>MetodoObtencaoVazoes</th>\n      <th>Maxima</th>\n      <th>Minima</th>\n      <th>Media</th>\n      <th>DiaMaxima</th>\n      <th>...</th>\n      <th>Vazao24Status</th>\n      <th>Vazao25Status</th>\n      <th>Vazao26Status</th>\n      <th>Vazao27Status</th>\n      <th>Vazao28Status</th>\n      <th>Vazao29Status</th>\n      <th>Vazao30Status</th>\n      <th>Vazao31Status</th>\n      <th>hydro_month</th>\n      <th>hydro_year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>699</th>\n      <td>67100000</td>\n      <td>1</td>\n      <td>2022-02-01</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1102.199</td>\n      <td>1010.538</td>\n      <td>1064.722</td>\n      <td>26</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6</td>\n      <td>2022</td>\n    </tr>\n    <tr>\n      <th>700</th>\n      <td>67100000</td>\n      <td>1</td>\n      <td>2022-03-01</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1297.883</td>\n      <td>1102.199</td>\n      <td>1176.588</td>\n      <td>31</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>7</td>\n      <td>2022</td>\n    </tr>\n    <tr>\n      <th>701</th>\n      <td>67100000</td>\n      <td>1</td>\n      <td>2022-04-01</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1422.217</td>\n      <td>1283.357</td>\n      <td>1360.572</td>\n      <td>21</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>8</td>\n      <td>2022</td>\n    </tr>\n    <tr>\n      <th>702</th>\n      <td>67100000</td>\n      <td>1</td>\n      <td>2022-05-01</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1491.803</td>\n      <td>1394.359</td>\n      <td>1446.903</td>\n      <td>29</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>9</td>\n      <td>2022</td>\n    </tr>\n    <tr>\n      <th>703</th>\n      <td>67100000</td>\n      <td>1</td>\n      <td>2022-06-01</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1541.801</td>\n      <td>1483.986</td>\n      <td>1515.262</td>\n      <td>27</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>10</td>\n      <td>2022</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 80 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = [str(num) for num in range(1965, 2023) for _ in range(12)]\n",
    "df[\"hydro_year\"] = list(islice(cycle(years), len(df)))\n",
    "df = df.drop(df.tail(2).index)\n",
    "df.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T18:00:31.812538Z",
     "start_time": "2024-09-27T18:00:31.779999300Z"
    }
   },
   "id": "4f8d9eacb8f4ee2f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1942\u001B[0m, in \u001B[0;36mGroupBy._agg_py_fallback\u001B[1;34m(self, how, values, ndim, alt)\u001B[0m\n\u001B[0;32m   1941\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1942\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_grouper\u001B[38;5;241m.\u001B[39magg_series(ser, alt, preserve_dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m   1943\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:864\u001B[0m, in \u001B[0;36mBaseGrouper.agg_series\u001B[1;34m(self, obj, func, preserve_dtype)\u001B[0m\n\u001B[0;32m    862\u001B[0m     preserve_dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 864\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aggregate_series_pure_python(obj, func)\n\u001B[0;32m    866\u001B[0m npvalues \u001B[38;5;241m=\u001B[39m lib\u001B[38;5;241m.\u001B[39mmaybe_convert_objects(result, try_float\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:885\u001B[0m, in \u001B[0;36mBaseGrouper._aggregate_series_pure_python\u001B[1;34m(self, obj, func)\u001B[0m\n\u001B[0;32m    884\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(splitter):\n\u001B[1;32m--> 885\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(group)\n\u001B[0;32m    886\u001B[0m     res \u001B[38;5;241m=\u001B[39m extract_result(res)\n",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2454\u001B[0m, in \u001B[0;36mGroupBy.mean.<locals>.<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m   2451\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2452\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cython_agg_general(\n\u001B[0;32m   2453\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m-> 2454\u001B[0m         alt\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: Series(x, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\u001B[38;5;241m.\u001B[39mmean(numeric_only\u001B[38;5;241m=\u001B[39mnumeric_only),\n\u001B[0;32m   2455\u001B[0m         numeric_only\u001B[38;5;241m=\u001B[39mnumeric_only,\n\u001B[0;32m   2456\u001B[0m     )\n\u001B[0;32m   2457\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgroupby\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6540\u001B[0m, in \u001B[0;36mSeries.mean\u001B[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m   6532\u001B[0m \u001B[38;5;129m@doc\u001B[39m(make_doc(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m, ndim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m   6533\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmean\u001B[39m(\n\u001B[0;32m   6534\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   6538\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   6539\u001B[0m ):\n\u001B[1;32m-> 6540\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m NDFrame\u001B[38;5;241m.\u001B[39mmean(\u001B[38;5;28mself\u001B[39m, axis, skipna, numeric_only, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12417\u001B[0m, in \u001B[0;36mNDFrame.mean\u001B[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  12410\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmean\u001B[39m(\n\u001B[0;32m  12411\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m  12412\u001B[0m     axis: Axis \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m  12415\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m  12416\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Series \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mfloat\u001B[39m:\n\u001B[1;32m> 12417\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stat_function(\n\u001B[0;32m  12418\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m, nanops\u001B[38;5;241m.\u001B[39mnanmean, axis, skipna, numeric_only, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m  12419\u001B[0m     )\n",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12374\u001B[0m, in \u001B[0;36mNDFrame._stat_function\u001B[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  12372\u001B[0m validate_bool_kwarg(skipna, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskipna\u001B[39m\u001B[38;5;124m\"\u001B[39m, none_allowed\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m> 12374\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reduce(\n\u001B[0;32m  12375\u001B[0m     func, name\u001B[38;5;241m=\u001B[39mname, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, numeric_only\u001B[38;5;241m=\u001B[39mnumeric_only\n\u001B[0;32m  12376\u001B[0m )\n",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6448\u001B[0m, in \u001B[0;36mSeries._reduce\u001B[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001B[0m\n\u001B[0;32m   6444\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m   6445\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSeries.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not allow \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkwd_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumeric_only\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   6446\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwith non-numeric dtypes.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   6447\u001B[0m     )\n\u001B[1;32m-> 6448\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m op(delegate, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001B[0m, in \u001B[0;36mbottleneck_switch.__call__.<locals>.f\u001B[1;34m(values, axis, skipna, **kwds)\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 147\u001B[0m     result \u001B[38;5;241m=\u001B[39m alt(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001B[0m, in \u001B[0;36m_datetimelike_compat.<locals>.new_func\u001B[1;34m(values, axis, skipna, mask, **kwargs)\u001B[0m\n\u001B[0;32m    402\u001B[0m     mask \u001B[38;5;241m=\u001B[39m isna(values)\n\u001B[1;32m--> 404\u001B[0m result \u001B[38;5;241m=\u001B[39m func(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, mask\u001B[38;5;241m=\u001B[39mmask, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    406\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m datetimelike:\n",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:720\u001B[0m, in \u001B[0;36mnanmean\u001B[1;34m(values, axis, skipna, mask)\u001B[0m\n\u001B[0;32m    719\u001B[0m the_sum \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39msum(axis, dtype\u001B[38;5;241m=\u001B[39mdtype_sum)\n\u001B[1;32m--> 720\u001B[0m the_sum \u001B[38;5;241m=\u001B[39m _ensure_numeric(the_sum)\n\u001B[0;32m    722\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(the_sum, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:1701\u001B[0m, in \u001B[0;36m_ensure_numeric\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m   1699\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m   1700\u001B[0m     \u001B[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001B[39;00m\n\u001B[1;32m-> 1701\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not convert string \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m to numeric\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1702\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[1;31mTypeError\u001B[0m: Could not convert string '123456789101112' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrunoff\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMedia\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mfloat\u001B[39m)\n\u001B[0;32m      2\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhydro_year\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhydro_year\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m df_year \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhydro_year\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m      4\u001B[0m df_year \u001B[38;5;241m=\u001B[39m df_year\u001B[38;5;241m.\u001B[39mreset_index()\n\u001B[0;32m      5\u001B[0m df_year\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2452\u001B[0m, in \u001B[0;36mGroupBy.mean\u001B[1;34m(self, numeric_only, engine, engine_kwargs)\u001B[0m\n\u001B[0;32m   2445\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_numba_agg_general(\n\u001B[0;32m   2446\u001B[0m         grouped_mean,\n\u001B[0;32m   2447\u001B[0m         executor\u001B[38;5;241m.\u001B[39mfloat_dtype_mapping,\n\u001B[0;32m   2448\u001B[0m         engine_kwargs,\n\u001B[0;32m   2449\u001B[0m         min_periods\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[0;32m   2450\u001B[0m     )\n\u001B[0;32m   2451\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2452\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cython_agg_general(\n\u001B[0;32m   2453\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   2454\u001B[0m         alt\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: Series(x, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\u001B[38;5;241m.\u001B[39mmean(numeric_only\u001B[38;5;241m=\u001B[39mnumeric_only),\n\u001B[0;32m   2455\u001B[0m         numeric_only\u001B[38;5;241m=\u001B[39mnumeric_only,\n\u001B[0;32m   2456\u001B[0m     )\n\u001B[0;32m   2457\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgroupby\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1998\u001B[0m, in \u001B[0;36mGroupBy._cython_agg_general\u001B[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001B[0m\n\u001B[0;32m   1995\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_agg_py_fallback(how, values, ndim\u001B[38;5;241m=\u001B[39mdata\u001B[38;5;241m.\u001B[39mndim, alt\u001B[38;5;241m=\u001B[39malt)\n\u001B[0;32m   1996\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[1;32m-> 1998\u001B[0m new_mgr \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mgrouped_reduce(array_func)\n\u001B[0;32m   1999\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wrap_agged_manager(new_mgr)\n\u001B[0;32m   2000\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m how \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124midxmin\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124midxmax\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1469\u001B[0m, in \u001B[0;36mBlockManager.grouped_reduce\u001B[1;34m(self, func)\u001B[0m\n\u001B[0;32m   1465\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m blk\u001B[38;5;241m.\u001B[39mis_object:\n\u001B[0;32m   1466\u001B[0m     \u001B[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001B[39;00m\n\u001B[0;32m   1467\u001B[0m     \u001B[38;5;66;03m#  while others do not.\u001B[39;00m\n\u001B[0;32m   1468\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m sb \u001B[38;5;129;01min\u001B[39;00m blk\u001B[38;5;241m.\u001B[39m_split():\n\u001B[1;32m-> 1469\u001B[0m         applied \u001B[38;5;241m=\u001B[39m sb\u001B[38;5;241m.\u001B[39mapply(func)\n\u001B[0;32m   1470\u001B[0m         result_blocks \u001B[38;5;241m=\u001B[39m extend_blocks(applied, result_blocks)\n\u001B[0;32m   1471\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:393\u001B[0m, in \u001B[0;36mBlock.apply\u001B[1;34m(self, func, **kwargs)\u001B[0m\n\u001B[0;32m    387\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[0;32m    388\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[Block]:\n\u001B[0;32m    389\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    390\u001B[0m \u001B[38;5;124;03m    apply the function to my values; return a block if we are not\u001B[39;00m\n\u001B[0;32m    391\u001B[0m \u001B[38;5;124;03m    one\u001B[39;00m\n\u001B[0;32m    392\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 393\u001B[0m     result \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    395\u001B[0m     result \u001B[38;5;241m=\u001B[39m maybe_coerce_values(result)\n\u001B[0;32m    396\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_split_op_result(result)\n",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1995\u001B[0m, in \u001B[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001B[1;34m(values)\u001B[0m\n\u001B[0;32m   1992\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[0;32m   1994\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m alt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1995\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_agg_py_fallback(how, values, ndim\u001B[38;5;241m=\u001B[39mdata\u001B[38;5;241m.\u001B[39mndim, alt\u001B[38;5;241m=\u001B[39malt)\n\u001B[0;32m   1996\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mC:\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1946\u001B[0m, in \u001B[0;36mGroupBy._agg_py_fallback\u001B[1;34m(self, how, values, ndim, alt)\u001B[0m\n\u001B[0;32m   1944\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124magg function failed [how->\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhow\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,dtype->\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mser\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1945\u001B[0m     \u001B[38;5;66;03m# preserve the kind of exception that raised\u001B[39;00m\n\u001B[1;32m-> 1946\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(err)(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   1948\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ser\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m:\n\u001B[0;32m   1949\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m res_values\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mTypeError\u001B[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "df['runoff'] = df['runoff'].astype(float)\n",
    "df['hydro_year'] = df['hydro_year'].astype(int)\n",
    "df_year = df.groupby('hydro_year').mean()\n",
    "df_year = df_year.reset_index()\n",
    "df_year.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-27T18:01:03.220030900Z",
     "start_time": "2024-09-27T18:01:01.494072600Z"
    }
   },
   "id": "d83de255f358a2b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BH = gpd.read_file('Data/BAP_PortoMurtinho.shp')\n",
    "# Define the area of the basin in square meters\n",
    "area = 583798255228"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e20b1edde3ac9e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert runoff from m³/s to mm\n",
    "df_year['runoff_mm'] = (df_year['runoff'] * 31536000 * 1000) / (area)\n",
    "df_year.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "912bc21ef78dd094"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_year.to_csv('Data/ANA_Runoff.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50f632d089eb3d6f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Potential Evapotranspiration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b06383a2068888cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/raw_data/PET_ERA5.csv')\n",
    "df = df.rename(columns={'system:index': 'year'}) \n",
    "df = df.rename(columns={'system:index.1': 'month'}) \n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "469588351b4ca8fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Calculating the PET for the hydrologycal year \n",
    "#Hydrologycal years starts in September\n",
    "hidro_months = ['5', '6', '7', '8', '9', '10', '11', '12', '1', '2', '3', '4']\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddc35727058ac201"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from itertools import cycle, islice\n",
    "df[\"hydro_month\"] = list(islice(cycle(hidro_months), len(df)))\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f83c4263cd34540"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(df.index[:8])\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78b34cf307fc1856"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "years = [str(num) for num in range(1951, 2023) for _ in range(12)]\n",
    "df[\"hydro_year\"] = list(islice(cycle(years), len(df)))\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9ccf1928b5e2bf4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(df.tail(4).index)\n",
    "df.tail(20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81055bec830f4143"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['PET'] = df['ETr'].astype(float)\n",
    "df['hydro_year'] = df['hydro_year'].astype(int)\n",
    "df.groupby('hydro_year')['ETr'].sum().to_csv('Data/ERA-5_annualPET_BHPM.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13989598e56d98bb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Temperature"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73ee52ee65cf9d0a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/raw_data/TEMP_ERA5.csv')\n",
    "df = df.rename(columns={'TEMP': 'TEMP_raw'})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a563baa47bee55f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Add a new column transforming from Kevin to Celsius\n",
    "df['TEMP'] = df.apply(lambda row: (row.TEMP_raw - 273.15), axis = 1)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a13753b6358e1e8a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Calculating the Temperature for the hydrologycal year \n",
    "# Hydrologycal years starts in September \n",
    "hidro_months = ['6', '7', '8', '9', '10', '11', '12', '1', '2', '3', '4', '5']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aeec40b5c46acae6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from itertools import cycle, islice\n",
    "df[\"hydro_month\"] = list(islice(cycle(hidro_months), len(df)))\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eddad80129a154ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop(df.index[:7])\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a53d7ef86595833"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "years = [str(num) for num in range(1951, 2023) for _ in range(12)]\n",
    "df[\"hydro_year\"] = list(islice(cycle(years), len(df)))\n",
    "df = df.drop(df.tail(4).index)\n",
    "df.tail()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b052fe10cccb61f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['TEMP'] = df['TEMP'].astype(float)\n",
    "df['hydro_year'] = df['hydro_year'].astype(int)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54c76768b1eb4fb1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.groupby('hydro_year')['TEMP'].mean().to_csv('Data/ERA-5_annualTEMP_BHPM.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2356d72ca399f846"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VPD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff3c1459016eef49"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculating VPD:\n",
    "Vapor Pressure Deficit = es - ea\n",
    "\n",
    "es = 0.6108\n",
    "exp((17.27 * T) / (237.3 + T))\n",
    "\n",
    "Relative humidity can be approximated from air and dew point by\n",
    "rh = 100((112 ‐ 0.1T + D) / 112 + 0.9 T)\n",
    "T = temperature\n",
    "D = dew point\n",
    "\n",
    "ea = es * rh / 100"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f5cc8ea3facb791"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/cassi/trabalhos/pantanal-lc/ERA-5/BHPM/raw data/ERA5_clima_BHPM.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f0f14ea58f07062"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['VPD'] = df.apply(lambda row: row['e_s'] - row['e_a'], axis=1)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "692b3083c545f8eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"system:index\"] = pd.to_datetime(df[\"system:index\"], format=\"%Y-%m-%d\")\n",
    "df = df.groupby([df[\"system:index\"].dt.year, df[\"system:index\"].dt.month])[\"VPD\"].mean()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7792b469e39eac48"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Calculating the VPD for the hydrologycal year \n",
    "#Hydrologycal years starts in September \n",
    "hidro_months = ['6', '7', '8', '9', '10', '11', '12', '1', '2', '3', '4', '5']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ebdec86a36207b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from itertools import cycle, islice\n",
    "merged_df[\"hydro_month\"] = list(islice(cycle(hidro_months), len(merged_df)))\n",
    "merged_df.head(10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "803b94e8b56dbd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop(merged_df.index[:7])\n",
    "merged_df.head(10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fecd1fb6065da7eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "years = [str(num) for num in range(1951, 2023) for _ in range(12)]\n",
    "merged_df[\"hydro_year\"] = list(islice(cycle(years), len(merged_df)))\n",
    "merged_df = merged_df.drop(merged_df.tail(4).index)\n",
    "merged_df.tail()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdcdb864403d4c49"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df['VPD'] = merged_df['VPD'].astype(float)\n",
    "merged_df['hydro_year'] = merged_df['hydro_year'].astype(int)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "226fa74b0ee51080"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df.groupby('hydro_year')['VPD'].mean().to_csv('Data/ERA-5_annualVPD_BHPM.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b1eee0fe5a23f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "aa8ef626a22ce320"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98d4166ba14fc5a6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
